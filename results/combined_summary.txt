Combined Summary of All Papers:

1.4 ISSCC 2024 / SESSION 1 / PLENARY . 1.4. Fueling Semiconductor Innovation and Entrepreneurship in the Next Decade Lip-Bu Tan Chairman of Walden International, Founding Managing partner . this paper provides a comprehensive overview of the future of semiconductor technology . it discusses the semiconductor industry’s current state, entrepreneurship’s role in driving innovation, and potential future developments in this field . the paper highlights the virtuous cycle of innovation and entrepreneurship, where advancements in semiconductor technology fuel new business opportunities . this cycle is crucial for creating the next generation of intelligent electronic systems . Moore’s Law has been a driving force behind innovation in the electronics industry and various application market segments . Intel, as a key participant in the semiconductor industry, has been instrumental in delivering innovation that aligns with Moore's Law . paper explores the “stack” of semiconductor technology, from materials and design to manufacturing and generative AI applications . it establishes beneficial relationships between layers of the stack, with advancements in one area often enabling progress in others . pursuing technologies that can contribute to a better world has become paramount in today’s ever-evolving world . a holistic approach to innovation in the semiconductor industry can collectively drive the industry forward . technologies for an better world have become a key component of the industry . in this paper, we will explore a range of technologies that have the power to shape a better world . we will focus on various technological advancements across different sectors . each seeking the path to positive impact (Figure 1.4.3). delve into how these technologies can pave the way for a brighter future . by harnessing the power of cutting-edge technologies, we can tackle pressing issues such as climate change, healthcare accessibility, urbanization, and education inequality . we can achieve a more sustainable, inclusive, and prosperous future by understanding their capabilities and envisioning their applications . join us as we delve into the technologies that promise a better world for all . we have moved beyond Moore’s Law to enter an era of limitless potential enabled by silicon . semiconductors are the quintessential enablers of the electric vehicle revolution . sustainability is not just an industry trend but a societal transformation . the semiconductor industry is responding to a call for more sustainable investment . generative AI acts as a force multiplier for human creativity and decision-making . it enables the rapid prototyping of ideas, automates mundane tasks, and opens new avenues for personalized services . Generative AI is a transformational technology that can redefine many sectors, from content creation to data analysis . generative AI can solve complex problems, such as digital biology, that require synthesizing vast amounts of information . it has the potential to create entirely new workflows, driving innovation and offering solutions to longstanding challenges . the AI is a powerful tool that can be used to solve complex complex problems like digital biology . 2.3 Digital Biology Digital biology revolutionizes our understanding of life sciences, bridging the gap between biological systems and computational models . it is a leap forward in our ability to understand and manipulate the world around us . 2.3 digital biology is an incremental improvement over existing systems . digital biology enables a more nuanced understanding of complex biological phenomena, from cellular processes to ecosystems . biosimulation can aid in drug discovery, personalized treatments, and the monitoring of diseases in real-time . 3.1 AI – The Computational Workhorse We are not just improving algorithms but rethinking computer architecture from the ground up . the industry benefits from an unprecedented combination of drivers: AI, Hyperscale Computing, 5G, Autonomous Vehicles, and Industrial IoT . the rising demand for workload-specific AI systems will dramatically transform system design . traditional serial processing architecture often needs more efficiency and speed . as AI applications diversify from natural language processing to simulation and autonomous driving there will be a growing need for specialized hardware to optimize these workloads . this shift will lead to a new generation of processors that feature a blend of CPUs, GPUs, TPUs, and even custom ASICs . by aligning hardware more closely with workloads, these architectural changes will likely result in significantly higher performance, reduced energy consumption, and more rapid advancements in AI capabilities. 3.2 Hyperscale Computing – The Backbone of the digital world In a hyperscale world, semiconductors are the spine underpinning the vast networks of servers and data centers that power today’s digital world . 3.2 hyperscale computing – the backbone of a digital world. semiconductors ranging from CPUs and GPUs to specialized chips provide computational horsepower necessary for real-time data analytics, machine learning, and other high-demand applications . matrixed variants provide the computational horsepower needed for real time data analytics and machine learning . advancements in semiconductor technology, such as smaller transistor sizes and more energy-efficient designs, directly influence the capabilities and economics of hyperscale operations . hyperscale is the engine of the hyperscale architecture, enabling cloud providers to deliver services at unprecedented scales . 3.3 5G – The Lifeline of Connectivity 5G is more than just an incremental upgrade over its predecessors . it represents a paradigm shift driven mainly by advancements in semiconductor technology . the lifeline of connectivity 5G represents the foundational element that makes the hyperscale world function efficiently and effectively . 5G aims to unify the connectivity fabric for various applications . the high-frequency, low-latency, and energy-efficient semiconductors at the heart of 5G networks make these ambitious goals achievable . 5G is a mobile network that focuses on voice and essential data services . 5G is poised to be the lifeline of a more interconnected and real-time world . it is not just about faster smartphones; it is about enabling a unique ecosystem of connected technologies made possible by cutting-edge semiconductor innovations . 2024 IEEE International Solid-State Circuits Conference (ISSCC) | 979-8-3503-0620-0/24/$31.00 2024 IEEE . downloaded on march 05,2025 at 00:21:27 UTC from IEEE Xplore. the expected growth of autonomous vehicles will significantly expand the semiconductor market in several ways . traditional cars typically include $350 - $400 in semiconductors . a) Increased Semiconductor Content: traditional vehicles typically include $600 - $600 in semiconductor . by the end of the current decade, semiconductor content is projected to exceed 20% of the BOM value of premium vehicles . each autonomous vehicle is expected to have about 200-400 sensors for various functionalities like lidar, radar, and cameras . autonomous vehicles generate about four terabytes of data per hour [3], requiring advanced processors and high-capacity storage solutions . connectivity: 5G and vehicle-to-everything (V2X) communication are vital for real-time data transmission . autonomous vehicles are often electric, requiring complex power management systems and additional semiconductor components like power MOSFETs, IGBTs, and more . the sheer number of such vehicles on the road will necessitate massive quantities of semiconductors . the addition of cybersecurity features to protect autonomous vehicles from hacking will also increase semiconductor usage . in-car entertainment and navigation systems, part of the autonomous vehicle experience, will require additional semiconductor components . h) safety and security: a new cybersecurity feature will also protect vehicles against hacking . the adoption and growth of autonomous vehicles will be a significant driver for the semiconductor market, contributing tens of billions of dollars in additional revenue . the IoT Quilt The Internet of Things (IoT) is fundamentally driven by innovations in silicon technology, serving as the bedrock of an interconnected ecosystem of devices. IoT devices can perform complex tasks while operating in energy-constrained environments . a critical requirement for applications ranging from smart homes and wearables to industrial automation and healthcare monitoring . smart homes, wearable devices and smart homes can also be used to perform tasks in a complex environment . silicon innovation-equip IoT devices have the ability to collect data, process it locally or in the cloud, and interact with other devices in real-time . the very scalability and affordability of silicon solutions are a direct consequence of advancements in silicon technology . silicon innovation is the catalyst for transforming the promise of IoT from a conceptual vision into a transformative, ubiquitous reality . the importance of system design in a full-stack approach, known as Software 2.0, must be considered . a well-designed system in this context optimizes model performance, scalability, and maintainability while ensuring seamless data flow and real-time analytics . a system that integrates not just the application and database layers but also data pipelines, model training and inferencing components . holistic approach to system design is vital for the success of projects in the software 2.0 era . a holistic approach is crucial in harmonising traditional software elements with machine learning components, providing that the system can evolve without significant friction as technology advances . the emergence of generative AI is a driving force behind technological advancements in semiconductors, networking, and storage and the rapid development of edge infrastructure . in essence, generative artificial intelligence is driving innovation and upgrades across multiple technological domains . 5.1 Semiconductor innovations The computational complexity of generative AI models requires specialized hardware for efficient processing . traditional general-purpose CPUs often need to catch up in handling the specific needs of these applications . generative artificial intelligence models are designed to meet the evolving computational demands and unlock the full potential of applications. there is a surge in the development of specialized semiconductors to meet the high-throughput and low-latency requirements of generative AI . custom ASICs can handle specific tasks more efficiently in terms of speed and energy consumption . high-performance internet switches are critical for real-time processing and analysis . the architecture might require network scaling to incorporate faster technologies like 5G to maintain real time data exchange and analytics . if the architecture isn't optimized, the architecture could require a faster network scaling . 5.3 new storage innovations and software optimization Traditional storage solutions like DRAM and SRAM are fast but come with limitations in terms of cost and capacity . emerging technologies are under development to make the most efficient use of available storage and computational resources . the need for real-time analytics drives the rapid growth of edge infrastructure . moving computation closer to the data source in edge computing setups reduces latency and conserves bandwidth, enabling generative AI applications to operate more effectively and efficiently . the rise of Purpose-Built Silicon Silicon is experiencing a renaissance . one size does not fit all, a trend that emerged as a response to the increasingly diverse and complex demands of modern computing . processors like GPUs for graphics processing, TPUs for machine learning, and ASICs for custom applications offer optimized performance that general-purpose CPUs cannot match . the need for chips that can perform special functions at high speeds and low power consumption has soared . specialized chips can implement tasks more efficiently, reducing energy costs and latency while increasing throughput . this shift towards specialization is a strategic adaptation to a landscape where computational workloads are becoming more varied and specialized, requiring tailored hardware solutions for optimal performance . 7.1 design Flow Automation The state-of-the-art chip design methodology involves a series of transformation, analysis, and optimization steps . over time, the pressure on performance, the convergence of physics with advanced nodes, and the need to co-design to reduce schedules have introduced loops in the design flow . AI-driven chip design and implementation tools allow engineers to concurrently optimize the flow for multiple blocks . full-flow reinforcement learning technology significantly improves the engineering team productivity . an example of an AI tool for chip design is the Cadence ® CerebrusTM Intelligent Chip Explorer . it automates the flow to optimize performance, power, and area (PPA) of the formerly manually guided tools and optimizations, uses reinforcement learning to make decisions . it incorporates trained models for learning from previous runs . IC packaging was much simpler ten years ago, so empirical models sufficed . today’s multi-chip models require electrical models . if an IC designer needs to account for what is happening on the package, chances are that the chip will not work . AI-driven package layout tools can reduce time to produce IC packaging while optimizing signal integrity . IC designers gain confidence that their chip will work once placed in the package and then on the PCB before building a design . the Cadence Virtuoso ® Studio can design the package with the IC design data and consider the PCB requirements to create an optimal solution . 7.3 Verification Digital simulation has been the workhorse of logic verification for decades . the digital verification norms are large-scale regression suites, massive server farms or cloud deployments and regression management technologies . a generational shift from single-run, single-engine simulation regression algorithms to new technology that leverages big data and AI across multiple runs of multiple engines . the technology can optimize verification workloads, boost coverage, and accelerate root cause analysis of bugs . an example of an AI-driven verification solution is the Cadence VerisiumTM AI-Driven Platform . the technology reduces the time to create clean designs at the start of verification projects . it offers unique capabilities for automating regression triage, mining waveforms for a bug root cause, analyzing reports and log files to determine bug causality in source code check-ins . the existing technology was used to grind out designs, sometimes running for days . generative AI technology reduces placement and routing tasks from days to minutes . the technology automates component placement, power plane creation, and routing critical nets . an example of an AI tool for PCB design is the Cadences Allegro ® X AI system design technology . 7.5 System Design Parametric sweeps consume large amounts of analysis time and computational resources . it uses AI to find optimal routing, often an order-of-magnitude faster, enabling exploration of the solution space for a higher quality of results and creating a better starting layout . design engineers need an intelligent, accurate, easy-to-use simulation and analysis solution that reduces repetitive design cycles . AI-driven system optimization technology can explore a broader state space, looking beyond local minima and maxima, and approach optimization more efficiently than a brute-force parametric study. the chip market is on an unprecedented growth trajectory, driven by a confluence of factors that extend beyond traditional computing needs . it uniquely optimizes system parameters for 3D electromagnetic analysis, high-speed signal and power integrity . we aim for a trillion-dollar semiconductor industry revenue by 2030 [6] the advent of 5G, IoT, AI, and autonomous vehicles has created a burgeoning demand for advanced, specialized semiconductor chips . the requirement for high-performance, energy-efficient, and secure semiconductors continues to escalate as digital transformation sweeps across sectors like healthcare, finance, and manufacturing . new technologies like 2.5D/3D packaging are paving the way for giant performance leaps . supply chain dynamics are also evolving, with emphasis on localized production and secure sourcing . financial investments in research and development (R&D) and semiconductor fabrication facilities are accelerating . call to action We stand at a pivotal moment in history where our collective innovation has the power to reshape the very fabric of society . from AI and 5G to healthcare and renewable energy, semiconductors are the invisible force driving progress . to sustain this momentum, we must double down on fostering innovation . innovation requires more than iterating on existing technologies . it will require investing in groundbreaking research that opens doors to new markets and applications . equally critical is the urgent need to address our industry’s skills shortage . talent is the lifeblood of innovation, and so must our workforce . industry internships, apprenticeships, and mentorship programs can bridge academic learning . by investing in the next generation of engineers, designers, and thinkers, we are investing in our industry’s long-term health and competitiveness . public-private partnerships can catalyze research, reduce risks, and quickly bring transformative technologies to market . in a world where geopolitical dynamics and global supply chain complexities increasingly impact our industry, we must stay caught up in research and development . by sustained, collaborative investment, we will continue to lead in innovation, create high-value jobs, and shape the future . let us seize this moment together and affirm our commitment to an industry that does not just change the rules but writes them . IEEE CIRCUITS AND SYSTEMS MAGAZINE 49Digital Object Identifier 10.1109/MCAS.2024.3395580 Date of current version: 15 August 2024CASS Conference Highlights Rajiv Joshi, Fellow, IEEE . the symposium featured 8 distinguished speak - ers (7 from industry and 1 from academia), over 30 stu - dent posters, best poster awards, and a panel discussion . the theme of the symposium, “From Chips to Chiplets,” turned out to be an opportune and important topic for the current semiconductor industry direction . the symposium served as an educational as well as a brainstorming session for industry/academia/students across the world . the symposium covered a range of topics from emerging device technology, chip and chiplet architecture, advanced packag - ing technologies, and how these topics drive the rapid growth of AI . Dr. Rajiv Joshi, General Chair and IEEE Life Fellow opened the symposium with welcoming re marks along with the goals and accomplishments of this symposium . he discussed how artificial intelligence is trans - forming our world and the demand for computing power is increasing at an unprecedented pace . he emphasized technology development in the semiconductor ecosystem is the key ingredient to making this happen . he shared the roadmap, challeng - es, and enablers of IBM research’s artificial intelligence unit (AIU) Chiplet and advanced packaging technolo are vital to enable the next generation of AIU. Synopsys gave a vivid talk on "Impedance Matching AI, EDA, Chips, and Chiplets" Approximately 35 students from two local high schools applauded loudly and commented that they understood most of it and conveyed the following messages . four key methods are explored in the talk: expanded use of AI, especially generative AI, improvements in design automation, novel chip archi - tectures, and the use of multi-die systems, informally “chiplets” each of these approaches has already dem - onstrated the ability to recapture some amount of clas, yet neither are they always aligned . the talk fo - cused on some of the challenges of the approaches and the resulting opportunities for them to work together . it can be thought of as a kind of im - pedance matching designed to preserve and amplify the improvements available from each source . this shift challenges the programmability of generalized solutions cherished by software developers . the central question arises: can the advantages of both paradigms be harmonized? if the two paradigms can be harmonised? can we find a way to blend the adaptability of general- purpose processors with the strength of specialized accelerators? the authors are with the IBM T. J. Watson Research Center, Yorktown Heights, NY 10598 USA . this approach envisages a synergistic hardware-software co-design strategy . the same silicon chip can be morphed and instantiated to support various dataflows via software . it offers the effi ciency of specialized accelerators while maintaining the flexibility needed to accommodate diverse applications through generalization . andre tost, Distinguished Engineer, IBM Watsonx Cli - ent Engineering, presented recent developments in the talk "Generative AI in the Enterprise World with wat - sonx" the advent of generative AI technol has revolutionized the enterprise world, transform -ing business processes and user experiences alike . this talk delves into real-world use cases that leverage genera - tive AI . these ideas address unique challenges that arise with the implementation of generative AI. strategies for addressing privacy, compliance, and trustworthiness Fig. 1. Dr. Huiming Bu (Left) delivering a keynote talk . Dr. Robert Aitken gave a presentation related to "Impedance Matching AI, EDA, Chips, and Chiplets" tHIRD QUARTER 2024 IEEE CIRCUITS AND SYSTEMS MAGAZINE 51concerns, as well as approaches for managing the in - creased resource consumption associated with this technology are explored . the use of Large Language Models to streamline processes, en - hance customer interactions, and unlock new business opportunities are showcased . ethical considerations that accompany generative AI are stressed by examining the importance of transparency in AI decision-making, and the need for compliant and repre - sentative training data . chip siz - es would like to increase beyond the reticle size limit by adding more functional blocks for high perfor mance computing . despite the high cost of the silicon fabrication process, silicon siz would prefer to add more and more functionality blocks . advanced packages based on RDL (Re-Distribution Layer), flip chip bonding, and TSV (Through Silicon Via) have been actively used for heterogeneous integration in electronic packages for the past decade . integration using advanced packaging technology (2.5D and 3D) and chiplets has been attracting a lot of attention as these approaches enable higher bandwidth with low power consumption at a reduced cost . more and more silicon fabrication processes are being adopted in package technology . the 2.5D silicon inter - poser architecture is widely used for vertical interconnections . the 3D stacking architecture is enabling small form factor, increasing signal speed, and reducing power consumption and power dissipation . HCB (Hybrid Cu Bonding) must be considered for next generation bonding solutions . recent advanced package technology and roadmap for the Samsung AVP business unit was shared for memory, mo - bile, and HPC products . generative AI and its associated benefits have received a tremendous amount of attention . so has the unprecedented amount of compute and energy required to train and serve these extremely complex models . vanced Micro Devices is a renowned innovator in the field of energy efficiency . the talk proposes adopting a holistic ap - proach to energy efficiency to address issues related to how to avoid overwhelming the world’s power grid and energy generation capabilities . to frame the challenge, trends in energy use for generative AI and where the power is consumed for modern training systems need to be understood . this approach involves the reduction of energy per computation through the use of lower precision math formats and associated al - gorithms . ad - vanced optical interconnects are the most powerful lever Fig. 3 . IEEE CIRCUITS AND SYSTEMS MAGAZINE THIRD QUARTER 2024 combines these improvements with algorithmic and hardware-software synergy for efficiently mapping AI problems onto the optimized system . a talk related to “Generative AI in the Enterprise World” and Samuel Naffziger describing “Technology and architecture Requirements for Energy Efficient AI” . Arif Khan, Sr. Group Director, Cadence, presented a great talk . ferentiation and disaggregation for Processors and SoCs in the Generative AI world . the es are adopted, then the history and recent develop . point to an ability to deliver the benefits of LLMs while reining in energy use . this past year, chatGPT was quite the phenomenon as generative AI hit the peak of the hype cycle . this presentation discussed key market trends driving AI and the demand for newer pro - cessor/SoC, chip-to-chip, and module architectures that address the needs of this space. the need for high numerical aperture EUV (High NA-EUV) at nodes beyond 3 nm reduces the reticle size by half . these diminishing silicon economies of scale have pushed foundries, EDA companies and the manufacturing ecosystem to enable chiplet designs . new developments in packaging technology (through-silicon vias and stacking, interposers, bridging, bump-pitch scaling) and standardization of die-to-die interfaces are providing technology gains to offset the challenges of interface bottlenecks . this talk also highlighted important stan - dards in memory, such as the latest LPDDR and HBM versions . key interface standards such as 112G/224G, peripheral component interconnect ex - press (PCIe) and Compute Express Link (CXL) are critical to these new architectures for AI products. the jug - gernaut for differentiation and disaggregation in the more-than-Moore era continues to build momentum . these trends and recent technology advances are explored through this talk . questions such as “Can AI be used to design the next 3D-IC AI proces - sors?” are explored . high-performance workloads demand on- package integration of heterogeneous processing units, on-package memory, and communication infrastructure such as co-packaged optics to meet the demands of the computing landscape in the generative AI era . universal chiplet interconnect Express (UCIe) is an open industry standard with a fully specified stack that comprehends plug-and-play interoperability of chiplets on a package . a stack of stacks comprehends the plug and play interface of chips on board with well-established and successful off-package interconnect standards such as PCI Express® . usages and key metrics associated with different technology choices in UCIe and how this open standard could evolve . a poster session as well as a panel discussion were conducted . the details of the program are listed in the following link . the AI Compute Symposium has expanded its participant base to include local Yorktown Heights high school students for the first time . the AI compute symposium is being held at the u.s. university of california in june . it will be held in july . this ini - tiative marks a significant step towards engaging and nurturing young talent in AI . it provides a unique plat - form for these students to immerse themselves in the latest trends in AI hardware and software . a high school student co-authored and presented a poster showcasing their re - search and insights alongside seasoned professionals . the symposium exposed the young and mature audience to future directions in technology and motivated all to pursue abundant opportunities in the field of chips, chiplets, and systems . Rajiv Joshi, Matthew Ziegler, and Jin-Ping Han Technical Program Committee Anna Topol, Kaoutar El Maghraoui, Krishnan Kailas, Xin Zhang, Arvind Kumar, Linda Rudin, Cheng Chi, Atom Watanabe, and John Rozen . Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models Anonymous Author(s) Affiliation Address email Abstract Characterizing materials with electron micrographs is a crucial task in fields such as semiconductors and quantum materials . in 3 this study, we propose an innovative backbone architecture for analyzing electron 4 micrographs . we create multi-modal representations by tok- 5 enizing them into patch sequences and, additionally, representing them as vision 6 graphs, commonly referred to as patch attributed graphs. Hier- 7 archical network structure architecture 8 facilitates information exchange between the multi-modal representations and 9 knowledge integration across different patch resolutions . we leverage 10 large language models (LLMs) to generate detailed technical descriptions of nano- 11 materials as auxiliary information to assist in the downstream task. cross-domain repre- 13 sentations predict the nanomaterial 14 category . multi-faceted approach promises a more comprehensive and accu- 15 rate representation and classification of micrographs for nanomaterial identification . 16 Our framework outperforms traditional methods, overcoming challenges posed by 17 distributional shifts . the precise design, development, 21 and testing of semiconductor devices is essential for ensuring the reliability, durability, and perfor- 22 mance of high-tech chips . the com- 20 munication systems, transportation systems, and space exploration are the foundation of modern electronics . advanced imaging and analysis techniques are key to fabricating 23 and integrating nanoscale components and enabling advanced inspection . sizes now reach 25 as small as 7 nm or even smaller . the size of the next-generation miniaturized semiconductor devices is now 25 . the increased complexity of producing chips under 7 26 nanometers introduces greater potential for error . the semiconductor industry uses 28 electron beam tools, including scanning and transmission electron microscopy, to create 29 high-resolution images of these devices . electron micrographs reveal the 30 complex microstructures of materials . they are crucial for the accurate design and evaluation of 31 semiconductor devices . these images facilitate monitoring of 33 the process and defect detection, enabling subsequent process optimization or design adjustments 34 to mitigate defects. the autolabeling of electron micrographs for nanomaterial identification remains a significant challenge . Figure 1 shows the challenges in nanomaterial iden- 36 tification tasks . the autolaabeling is a challenge, while 35 are advantageous . this is largely attributed to distributional shifts such as manufacturing variations 37 or material property changes . exacerbated by high intra-class dissimilarity within nanomaterials, 38 high inter-class similarity . do not distribute. multiple scales or spatial heterogeneity. we propose a 40 end-to-end framework for automatic nanomaterial identification . we hypothesize that electron micrographs exhibit 43 hierarchical dependencies among patches (segmented portions of an electron nanograph). the framework is based on network fusion 41 for multi-modal nanomaterial representation learning . these 44 dependencies can be captured using multiple patch sequences and vision graph structures at different 45 spatial resolutions . to explore this, we tokenize the electron micrographs into grid-like 46 patches to obtain a patch sequence . a cls>token to the patch sequence and a virtual node to the 50 vision graph encapsulates the entire patch sequence . this special token/virtual node captures 51 global graph information in their respective contexts. we aim to capture fine- and coarse-grained 52 hierarchical dependencies by treating the micrographs as sequence structures and vision graphs at 53 multiple scales of patch size . the macrographs are a sequence structure and a vision graph . the hierarchical network fusion (HNF) is a cascading network architec- 55 ture that enhances the classification accuracy by analyzing and integrating two complemen- 56 tary representations of electron micrographs . vision graphs are 57 created at various patch sizes . the HNF is a 61 multi-layered network featuring an inverted pyramid architecture that generates a multi-scale 62 representation of an electron micrograph by creating a series of patch sequences and vision 63 graphs at different scales of patch size . each layer represents the original 65 micrograph-based patch sequence and vision graph at a distinct scale . the HNF facilitates a 67 more comprehensive representation of the electron micrograph, capturing both fine- and 68 coarse-grained details . the patch embeddings are iteratively refined using 69 bidirectional Neural Ordinary Differential Equations (Neural ODEs) [ 20], while the Graph 70 Chebyshev Convolution (GCC) Networks [ 51,28] encode the vision graphs in a layer-wise 71 manner . a mixture-of-experts technique with a 72 gating mechanism optimally combines predictions from both modalities at each layer by 73 calculating a weighted sum of classification token and virtual node embedding . this facilitates an intermodal mutual information exchange, fos- 75 tering interaction and knowledge integration . this innovative 76 approach enables the seamless integration of causal information from patch sequences to 77 refine the vision graph embeddings . visual 78 graphs embedded structural and semantic information from the patch sequence . our framework constructs a multi-scale representation of a 80 micrograph . the aim is to preserve both high-level features and structural 81 information embedded in the graphs . a more comprehensive representation of the micrograph is possible . large 84 language models (LLMs) generate technical descriptions of nanomaterials, 85 including synthesis methods, properties, and applications . we pre-train smaller language 86 models (LMs) [ 30,52] through self-supervised masked language modeling [ 5,30] on 87 these generated textual descriptions . we 90 use a weighted sum-pooling attention mechanism to compute text-level embeddings 91 . we encapsulate the vast domain-specific knowledge present in the 92 text data . the LMs are able to compute contextualized token embedders for nanomaterial identification tasks . our approach leverages LLM-based technical descriptions on nanomaterials to 93 identify characteristic features that distinguish them from other nanomaterial categories . 94 incorporating domain-specific knowledge as auxiliary information for downstream training . the approach is based on 93 technical descriptions . electron micrograph classification task is a type of inductive learning 97 task . the task is to assign labels to new, unseen micrographs using a labeled dataset 98 2 denoted as DL= (IL,YL) ypred i=f(Ii)denote the multi-modal encoder predictions . l(,) denotes the cross-entropy 103 loss . the electron micrographs of the same nanomate-rial ( MEMS device) can exhibit a high degree of heterogeneity . electron micrographs across different nanomaterial categories exhibit a noteworthy degree of similarity . the figure provides a visual representation of the challenges of classifying electron nanographs in the SEM dataset([4]). the figure demonstrates the spatial heterogeneity of visual patterns in nanoparticles . our framework includes three methods: Zero-Shot Prompting Textual Explanations LLM LM Attention Pooling Text-level Embedding . a) b) Nearest Neighbour Graph Electron Micrograph Hierarchical Network Fusion (HNF) Output Layer (MHA layer) we 108 divide the micrograph into a grid of patches, each having dimensions of ppc, with prepresenting 109 the patch size . the number of patches along each spatial dimension is given by n=hw/p2 . 111 These patches are linearly transformed to create a new tensor, I′Rnd . to account for the position of each patch within the micrograph, we introduce 113 position embeddings . a k-nearest 116 neighbors graph is undirected and represents the connectivity of patches based on their pairwise 118 proximity . the graph structure is described by a binary adjacency matrix, ARnn . we tokenize electron micrographs by dividing them into grid-like patches . patches are connected by edges that represent pairwise visual similarity 124 using a nearest-neighbor graph technique . if patch jis 119 is one of the k-nearest neighbors of patch i, then Aij= 1; otherwise, Aj= 0. 120 3.2 Hierarchical network fusion (HNF) 121 We represent an electron nanograph as a vision 123 graph, where patches are the vision graph captures local patch relationships and 125 uses graph-structural priors to analyze pairwise spatial dependencies within the micrograph . 126 Additionally, we represent electron micrographs as a patch sequence, capturing pairwise 127 dependencies beyond the original sparse graph structure between different patches within a micro- 128 graph . we append a classification token to a patch sequence 130 to obtain an embedding of the entire patch sequence that captures global information . virtual edges represent the pairwise relations between each 133 real node and the virtual node . the virtual node embedding captures the dependencies 134 between nodes . we hypothesize that 135 electron micrographs exhibit hierarchical dependencies among patches . 136 multiple patch sequences can be captured at different spatial resolutions . hierarchical network fusion (HNF) is a cascading network architecture that constructs a 138 multi-scale representation of an electron micrograph by creating a series of patch sequences and 139 vision graphs at multiple scales . h1(l)h2(l+1)hn(l+1)hCLS (l+ 1) Layer (l + 1) VNVN Figure 3: Overview of the HNF module . HNF modules are based on a series of modules that have been developed by a team of experts . the HNF module utilizes a multi-layered network with increasing patch sizes to represent the electron micrograph-based patch sequence and vision graph at various scales . each layer involves bidirectional Neural ODEs and Graph Chebyshev convolution . a gating mechanism integrates cross-domain embeddings . the HNF module facilitates seamless information fusion . hl iandel i denotes the patch and node representation at layer lof patch or node . the HNF architecture synergistically combines patch sequences and vision graphs representations at 141 different scales . each layer of the network represents the original micrograph-based patch sequence and 144 vision graph . the network offers a more comprehensive representation of the micrograph . each layer uses a bidirectional Neural ODE (refer to the appendix) to iteratively refine patch 148 embeddings . Graph Chebyshev Convolution 150 Network maps high-dimensional discrete vision graph information to 151 low-dimensional node-level embeddings . 152 structural information embedded in graphs is optimally preserved . mixture-of-experts 153 (MOE) technique employs a gating mechanism to combine predictions from the bidirectional Neural 154 ODEs and the Graph Chebyshev Convolution methods . predictions are integrated through a weighted sum of their cls>token and virtual node embeddings . training objectives include 156 optimizing the weight distribution of the gating function for accurate classification of nanomaterial 157 categories in electron micrographs and training the methods using the weights determined by the 158 function . the training objectives are based on 156 optimizations for weight distribution . the framework aims to improve classification accuracy by leveraging the 159 strengths of multiple learning methods . the gating mechanism is combined with the individual modalities at higher 162 patch resolutions . a fused representation can be obtained by combining the fused information and the individual layers . our framework incorporates bidirectional Neural ODEs and Graph Chebyshev 163 networks to facilitate the exchange of mutual information between patch sequences and visual graphs 164 . this approach allows the patch 165 embeddings to be grounded with structural and semantic information from the vision graph . 168 3.3 Beyond Conventional Analysis: Leveraging LLMs for Nanomaterial Characterization 169 The advent of large pre-trained language models (LLMs) has significantly revolutionized performance in various natural 171 language processing tasks . small-scale language models lack the 173 strong logical reasoning capabilities of LLMs . 172 LMs are 175 computationally affordable for fine-tuning using labeled data for specialized task adaptation . general-purpose LLMs require significant computational resources for repurposing through 179 fine-tuning for task-specific customization . however, they do not provide access to token 180 embeddings and logits for downstream applications of smaller 177 LMs across various tasks . the language modeling as a service platform provides access to LLMs 182 via text-based API interaction through cloud-based services . but the integration of 183 vision graphs remains an underexplored area, opening up the possibility for innovative techniques 184 that combine language models and graph representation learning algorithms . our approach capitalizes on zero-shot chain-of-thought 186 (Zero-Shot CoT) . we pre- 187 train smaller LMs on the generated textual descriptions using the masked language modeling (MLM) 188 technique to learn expressive token embeddings for 189 . our work evaluates two LLMs: GPT-3.5-turbo, and Google 194 BARD1 . we then fine-tune smaller LMs for 190 downstream supervised multi-class classification task to compute 191 context-aware token embeddings . newer and larger extension of GPT-3.5 model from OpenAI excels in 195 languages and shows cost-effectiveness . Google BARD is significantly larger than 196 GPT 3.5 models . we also use a pre-trained small-scale LM, DeBERTa2[52] . 5 In the GPT-3.5-turbo and BARD, text generation diversity is mainly influenced by two parameters: 199 Top-p and temperature . top-p sets a probability threshold for token inclusion, 200 filtering out rare or common tokens to balance the output . the temperature parameter 201 dictates the randomness of generated text . high values foster creativity, while low values ensure 202 focused and deterministic outputs . the cost category indicates the price for using 1k tokens, while the date of last update category denotes the most recent date the knowledge base of the LLMs was updated . we access LLMs via the LMaaS platform using text-based 205 API interactions . we employ open-ended natural language prompts with task-specific instructions to 206 query the LLM, thereby generating detailed textual descriptions pertaining to the structure, properties, 207 and applications of given nanomaterials . using a tailored zero-shot prompt template, we guide 208 the LLMs through a series of chain-of-thought prompts[ 101], extracting comprehensive domain 209 knowledge embedded within the language model parameters . the customized CoT prompt format is as follows: 211 Prompt 1: Introduction: Provide an overview of the nanomaterial category and its signifi- cance in various fields. Prompt 3: Synthesis Methods: Explore different methods used to synthesize or fabricate nanomaterials in this category . Discuss their advantages and limitations . discuss how these prop- erties differ from bulk counterparts . Prompt 6:Surface Modification: Describe the strategies used to modify the surface properties of nanomaterials in this category, such as functionalization, coating, or doping. Explain how these modifications enhance their performance or enable specific applications. Prompt 7: Toxicity and Safety: Address potential health and environmental concerns associated with nanomaterials in this category . discuss studies on their toxicity, risk assessment, and safety measures to mitigate potential hazards . highlight emerging technologies, challenges, and areas of active exploration . 212 Querying the LLMs generates technical descriptions of nanomaterial categories . it provides valuable 213 insights into the characteristics, properties, and applications of different types of Nanomaterials . the 212 queries were generated by Query Query the lLMs. we will present our approach to integrating detailed textual descriptions into 216 a small-scale LM for pre-training through the masked language modeling technique . 217 fine-tuning for domain customization on the downstream supervised nanomaterial identification task . 218 LMs are fine-tuned using a smaller language model (LM) 219 to interpret and encode textual outputs generated by a larger language model . 220 the smaller LM as an intermediate network to bridge the LLMs and downstream classification layers . the large corpus of textual outputs is processed 223 by randomly masking out tokens in each sentence . the model is then trained to predict the masked 224 words . this process helps the model learn 225 the statistical relationships between words and phrases . we pre-train smaller general-purpose language models (referred to 227 asLM expl) using the MLM technique for domain customization . we then fine-tune the smaller LM for downstream task-specific adaptation to encapsulate the explanations 230 generated by LLMs . we input text sequences generated 231 6 by LLMs (denoted as Sexpl) into the LM explmodel, which then generates expressive, context-aware 232 embeddings for each token in the sentence . mrepresents the number 236 of tokens in Sexplanddis token embedder dimension . sum-pooling attention 237 mechanism computes a weighted sum of these token embeddings to encode the textual explanations 238 . htextRdcaptures the essence or core 242 of the domain knowledge as whole, extracted from the foundational LLMs for each nanomaterial . 243 We calculate the relevance score between the text-level embedding( htext) and the electron micrograph 244 representations ( hfus) obtained from the hierarchical network fusion(HNF, refer to section 3.2) the above operator computes the list of scores or probabilities for each nanomaterial . we 250 then select the appropriate/relevant nanomaterial text-level embedding . the arg max operator selects the nanomaterial for which the probability is maximized . this is a matching mecha- 254 nism that tries to find the best pairwise alignment among the various nanomaterial text-level embeddings ( htext 1, , c) and hfus obtained from the hierarchical network 256 fusion . we use backpropagation error in the downstream supervised multi-classification 257 task to fine-tune the smaller LMs . htext fus259 incorporates the expert knowledge obtained from foundational LLMs for the appropriate nanomaterial 260 . 261 3.4 Overall Method 262 Figure 2 provides an overview of the “MultiFusion-LLM” framework . a) Hierarchical Network Fusion tokenizes micrographs 264 into patches to obtain patch sequences and construct vision graphs . the 266 network has a multi-layered structure . each layer of the network consists of bidirectional Neural ODEs 267 and graph Chebyshev networks . it computes cross-modal 269 embeddings, denoted as hfus . LLMs for Incorporating Domain Knowledge: 272 We generate technical descriptions of nanomaterials, capturing a wide range of information including 273 structure, properties, and applications . table 274 8 provides a glimpse of the LLM-retrieved text obtained from GPT-3.5 turbo, specifically generated 275 to address natural language queries . masked language modeling (MLM) pre-train a smaller LM 276 on the generated descriptions . we then fine-tune this 277 small-scale LM on a downstream supervised task to encapsulate the generated explanations. the multi-head attention mechanism (MHA) [95] fuse text-level embeddings 281 htext fuswith hierarchical embedderings hfus, enabling the capture of contextually relevant information 282 . 283 focusing on and aligning high-level textual descriptions (text-level embeddings) with detailed visual 284 representations . we ensure a comprehensive understanding and analysis of 285 electron micrographs from both descriptive and visual perspectives . this approach helps mitigate 286 inherent limitations arising from high intra-class dissimilarity, high inter-class similarity, and 287 spatial heterogeneity in visual patterns across the electron micrographs . enhancing the 288 performance of nanomaterial identification tasks . the Query, Key, Value projections for 289 7 the text-level embedding htext fusfor each head has 292 follows: 293Qh fus=hfusWh Qtext . 296 Kh concat = [Kh text, Kh fus];Vh concat= [Vh text] (9)297 Softmax attention to integrate complementary information from the cross-domain embed- 298 dings . each head outputs a new vector representation that highlights the most relevant features in the 301 mono-domain embeddeds, tailored to specific aspects . 305 Oconcat = [O1 cross, O2 cross, OH cross] (12) pi=softmax Wycross (14)306 . dh 307 represents the dimensionality of the key/query/value for each head, and His the number of heads . pi308 represents the probability distribution across nanomaterial categories . we conduct 310 Zero-shot CoT prompting of LLMs to generate technical descriptions of nanomaterials and pre-train 311 small-scale LMs using masked language modeling . the MHA offers a multi-faceted approach to capture and align varied information 315 sources . it allows for a 316 robust, synergistic, and comprehensive representation of data, especially in contexts like nanomaterial 317 analysis where both modalities offer complementary insights . 318 4 Experiments And Results 319 4.1 Datasets 320 Our study primarily used the SEM dataset[ 4] to automate nanomaterial identification . the expert- 321 annotated dataset spans across 10 distinct categories, representing a broad range of nanomaterials 322 . the original dataset curators, [ 4], did not provide predefined splits for training, 327 validation, and testing . k-fold cross-validation method facilitated a fair comparison with popular baseline models in a competitive 329 benchmark setting . we extended our evaluation by leveraging several open-source 330 material benchmark datasets relevant to our study . these datasets were used to showcase the efficacy 331 of our proposed framework and its applicability in a broader context beyond the SEM dataset. the figure depicts the different types of nanomaterials found in the SEM dataset ([ 4]). we evaluated the effectiveness of our proposed framework through a comprehensive performance 334 analysis, comparing it to commonly used computer vision baseline models . our comparisons included 335 supervised learning models such as ConvNets and ViTs (as referenced in [ 2,1]), along with self- 336 techniques like Vision Contrastive Learning (VCL) to ensure a fair and rigorous comparison, we 338 conducted experiments with consistent settings across all algorithms . proposed framework 340 outperforms baseline models, showing a relative improvement of 25.8%in the Top-1 341 score and a marginal improvement of 5.34% in the Top-5 score compared to the next-best baseline 342 model, T2TViT ([110]). algorithms Parameters Top-1 Top-2 Top-3 Top-5ConvNetsAlexNet([65]) 5.70E+07 0.493 0.582 0.673 0.793 DenseNet ([57]) 2.72E+05 0.512 0.766 0.891 0.906 VGG([81]) 3.44E+0 0.517 0.644 0.717 0.779 GoogleNet(([84]) 7.41E+5 0.436 0.469  multifusion-LLM 346 is a robust solution to the challenges associated with nanomaterial identification in electron 347 micrographs . our compre- 349 hensive framework has outperformed traditional methods . it has demonstrated effectiveness and computational effi- 351 ciency, particularly with large datasets, thereby accelerating high-throughput screening and advancing 352 research holding implications for the advancement of the semiconductor industries . the semiconductor industry has a long history of developing a semiconductor industry . 353 9 6 Technical Appendix 354 Table 3 presents experimental findings comparing the proposed framework’s performance to various 355 supervised learning-based baseline models . we 356 use Graph Contrastive Learning (GCL, [ 114]) algorithms for additional comparison . the table presents the results of a comparative study between our proposed method and supervised-learning based GNNs, as well as self-supervised graph contrastive learning (GCL) algo-rithms, on the SEM dataset . Algorithms Parameters Top-1 Top-2 Top-3 Top-5GSLGBT[8] 7.09E+05 0.513 0.595 0.686 0.778 GRACE[115] 7.44E+0 0.581 0.646 0.711 0.773 BGRL[87] 6.92E+5 0.573 0.629 0.671 0.728InfoGraph[82] 6.82E+15 0.560 0.631 0.694 0.756Graph Neural NetworksAPPNP the micrographs fall 363 within the range of [-1, 1] . this normalization results in a downscaled and normalized micrograph . we tokenize them into discrete, 364 non-overlapping patches . electron micrographs as patch sequences 365 and construct vision graphs using the hierarchical network fusion method . we 366 set the value of K to 10, 6, and 4 for each layer, 367 resulting in a total of three layers . this process generates multi-scale vision graph and patch 368 sequences with patch resolution increasing of 16, 28 and 32 pixels . patch dimension (dpos) 369 and position embedding dimension ( d) are set to 64 . the framework is evaluated using a 370 10-fold cross-validation strategy . we have a few more hyperparameters set for the cross-modal attention layer . to enhance the performance of the MultiFusion-LLM framework, we employ two key strategies: a) 374 early stopping on the validation set, which halts training when the framework’s performance on the 375 validation data plateaus to prevent overfitting . a learning rate scheduler that 376 reduces the learning rate by half if the validation loss stagnates for five consecutive epochs. reducing 377 the learning rate can help the framework converge to a better solution and avoid overfitting . the proposed framework enhances the accuracy of multi-class classification tasks 380 by seamlessly integrating both large language models and small-scale language models 381 (LMs). the framework interacts with off-the-shelf LLMs through a 384 Language Model as a Service (LaMaaS) platform through the text-based API interactions . we used GPT-3.5-turbo and google bard as representative LLM . the hyperparameters 386 for our framework were not individually fine-tuned for each LLM . the maximum output token 389 sequence length is 4096 for GPT-3.5-turbo and 4000 for Google Bard . to optimize computational 390 resource use, the system is trained on eight V100 GPUs . each boasting 8 GB of GPU memory ensures the training process is completed within 392 a reasonable timeframe . we conducted each experiment twice and reported the averaged results . the hierarchical network fusion (HNF) is a multi-layered, cascading network 397 architecture designed to enhance the classification accuracy of electron micrographs . it integrates 398 two complementary representations at multiple layers: patch sequences, which assist in capturing 399 spatial dependencies among patches beyond pairwise dependencies . the techniques provide a detailed multi-scale rep- 401 resentation of the micrographs . the technique uses an inverted pyramid structure, incorporating increasing patch sizes at each layer, and 403 bidirectional Neural ODEs and Graph chebyshev convolution networks . a mixture-of-experts technique further optimizes the integration of these cross-domain modalities, 406 fostering efficient knowledge exchange and improving classification accuracy . using zero-shot CoT prompt- 408 ing, we generate detailed technical descriptions of nanomaterials . we pre-train smaller 409 LMs using masked language modeling (MLM) on these descriptions to facilitate domain-specific 410 customization . these pre-trained are then fine-tuned for task-specific adaptation to generate 411 contextualized token embeddings . we use the cross-modal multi-head attention 414 mechanism to integrate and align information from different modalities into a coherent and unified representation that 416 captures complex, hierarchical, and potentially cross modal patterns . 418 HNF LLM’s Output LayerElectron Micrograph Label Figure 5 . we use zero-shot CoT to generate technical textual descriptions and pre-train smaller language models (LMs) using masked language modeling . in the ablation study, we systematically disable individual methods to assess their respective contributions and importance . the goal of this study is to understand the impact or significance of specific methods on the overall performance of the framework . if you are using a method, you may be able to use a different method to assess your contribution . the experimental findings reveal the significance of the disabled methods . these results substantiate our hypothesis regarding the joint optimization of HNF and LLMs . ablated variants were compared to baseline . the results were based on a consistent decrease in performance metrics . ablated 419 variants were subsequently evaluated using the original framework 420 11 . this approach enables us to verify the effectiveness of 421 our methods, substantiate their design decisions, and justify their inclusion in the framework. the ablated variants exclude the hierarchical network 424 fusion (HNF), large language models (LLMs) and multi-head attention layer respectively . the abbreviation "w/o" 426 stands for "without" the findings from the ablation study are 428 presented in Table 4 . the “w/o HNF” variant performs much worse than the baseline . a drop of 17.53% inAvg-Precision showed a substantial decline in 429 performance . the “w/o MHA" variant exhibited a notable deterioration in performance 432 compared to the baseline . this is 433 attributed to the overly simplified linear operator in the output layer . the ablated variants showed a 435 consistent decline in performance metrics . 436 6.3 An In-Depth Empirical Insights into Nanomaterial Classification 437 We have conducted additional experiments to gauge the efficacy of our framework . 439 experimental results demonstrate that our proposed framework can generalize to 440 a wide range of nanomaterials . we use a confusion matrix 444 to ensure a fair 443 and thorough comparison with baseline models . we use standard metrics such as precision (P in 442 %), recall (R in %) and F1-score . confusion matrix provides insights into how it categorizes electron micrographs across 446 different nanomaterial categories . the metrics included in the confusion matrix are as follows: True 447 Positives (TP) represent micrographes that actually belong to a specific category but are incorrectly 449 classified or missed . False Positives (FP) represent micrographs that are correctly identified as not 450 belonging to a particular category . these metrics 452 evaluate the accuracy and effectiveness of our framework in micrograph categorization . Precision 453 (TP / (FP + TP) measures the proportion of correctly classified micrographs for a specific category, 454 while recall (FN / FN) measures a proportion of all micrographes of a category that were 455 accurately identified. our proposed framework can 459 be attributed to its reduced dependency on nanomaterial-specific relational inductive bias . the framework demonstrates a 457 relatively higher score in the classification of nanomaterial categories with a large number of labeled 458 instances . 461 CategoryMulti-class metrics Precision Recall F1 Score Biological 0.9310.009 0.9430.007 0.9350.013 Tips 0.9090.005 0.9190.008 0.9160.011 Fibres 0.9790.006 0.9650.012 0.9630.014 Porous Sponge 0.9250.010 Films Coated Surface 0.9380.005.0.9340.009.0.9410.08 Patterned surface 0.9460.0 6.4 Baseline Algorithms 462 We have categorized our baseline methods into four distinct groups . Graph Neural Networks (GNNs) 463 ([79,38]), Graph Contrastive Learning (GCL) [ 114] . we construct vision graphs to represent electron micrographs using the Top-K nearest neighbor 466 search technique . patches are treated as nodes, and pairwise associations 467 between nearest-neighbor nodes are represented as edges . for baselines, 468 avoid constructing multi-scale vision graphs with increasing patch resolution . instead, we set 469 the patch size to 32 pixels to reduce the complexity of the baseline models . baseline Graph Neural Networks (GNNs) are used 471 for the multi-class classification task on vision graphs through supervised learning . graph 472 contrastive learning algorithms (GCL) use several graph data augmentation strategies to 473 create multiple correlated views of a vision graph . GCL algorithms employ the Graph Attention 476 Network (GAT) as the node-level graph encoder . Graph-level embeddings are generated 477 by performing sum-pooling on the nodes . random forest 478 algorithm uses robust self-supervised graph-level embeddings to predict nanomaterial 479 categories . to evaluate the effectiveness of the 480 unsupervised embeddeds, we measure the classification accuracy on the holdout 481 data . baseline ConvNets ([ 2,1]) is trained through supervised learning to analyze patch sequences within 484 electron micrographs for classification tasks . baseline Vision 483 Transformers (ViTs) is used to analyze patches sequences . visual-contrastive learning 485 (VCL) techniques are self-supervised algorithms designed for contrastive learning in 486 computer vision tasks . we use the ResNet backbone architecture for feature extraction . in this example, we divided an electron micrograph into a grid of 33patches . the image presents various representations of the micrograph, including a regular grid, a sequence, and a graph representation from left to right . different approaches for processing these representations include ConvNets that operate on pixel grids . graphs represent patches as nodes and are constructed using a nearest neighbor search algorithm . each method offers a unique perspective for analyzing electron micrographs . 6.5 Hyperparameter studies 488 We performed an in-depth hyperparameter tuning . the hyperparameters were chosen from the following ranges: embedding 491 dimension (d)[32,64,128,256] and batch size (b) . the algorithm used random-search technique to achieve the optimal performance of our 493 proposed framework on the validation dataset . 494 for each experiment, we altered the hyperparameter under investigation to ascertain its impact on the 495 framework’s performance . d= 64 and 496 b= 48 . 497 (d, b), 32,48, 64,48)(128,48) (256,48), 0.941 0.947 0.935 0.927 . the dataset is divided into six distinct 500 defect classes . the 501 defect categories include pitted surfaces, scratches, rolled-in scale, crazing, patches, and 502 inclusion defects . each category contains 300 micrographs with a resolution of 200 200 pixels . 506 •CMI4 consisted of 600 high-resolution electron micrographs depicting corroding panels . a comparative analysis was performed using various standard algorithms to evaluate the effectiveness of our proposed approach . the proposed approach is specifically in the domain of multi-class classification tasks for surface 505 defect identification. each micrograph has been annotated by corrosion experts following ASTM-D1654 stan- 508 dards . the dataset includes 120 distinct 509 micrographs for each corrosion rating with a spatial resolution of 512 512 pixels . 513 contains 810 electron mi- 514 crographs, each depicting one of ten distinct material types . the diverse material categories encompass textures such as 517 sponge, orange peel, styrofoam, cotton, cracker, linen, brown bread, crumpled 518 aluminum foil and corduroy . 520 duct a comparative analysis of its performance against various standard algorithms within 521 the domain of multi-class identification tasks . 522 Figure 7: The NEU-SDD dataset contains six distinct defect categories found in hot-rolled steel strips . the KTH-TIPS dataset contains samples of electron micrographs of ten distinct materials . these materials are described in reference 5. Table 7 presents a comprehensive comparison of the performance achieved by our proposed approach 523 in contrast to various baseline methods . experimental results 524 demonstrate that our method achieves state-of-the-art performance on all datasets, underscoring the 525 efficacy and robustness of our framework . the results show that our framework achieves a state of the art performance . the table presents the comparative evaluation of our proposed framework’s performance against several benchmark algorithms on a variety of datasets . the table is based on an analysis of the proposed framework's performance compared to other benchmark algorithms . 6.7 Graph Chebyshev convolution 527 The graph convolution is a powerful tool in the realm of learning from graph-structured data . it can be computationally expensive for 529 large graphs . Graph Chebyshev Convolution 533 allows us to apply convolutional filters on graph-structured data based on the spectral graph convolution 534 approximation of the graph laplacian . the normalized laplacian matrix, denoted as L, is defined 536 as: 537L=D1/2AD1/2(15)538 . a 540 truncated expansion of Chebyshev polynomials is obtained . the Chebyshev polynomials are computed recursively using the following recurrence relation 542 . 543 Tk(L) =  I, ifk= 0 L,ifk = 1 2LTk1 (L),otherwise544 where Iis the identity matrix . ndenotes the 545 number of patches and dis the patch embedding dimension . () is a non-linear ReLU activation function applied element-wise . kRddis the 549 parameter matrix (weights) for the k-th order Chebyshev polynomial . 555 6.8 Neural Ordinary Differential Equations (NODE) represent a deep neural network model 557 designed for continuous-time systems . eiRddenotes 554 the node embedding . 559 The objective is to determine the evolution of z(t) by calculating its derivative with respect to time 560 to capture the temporal dynamics of the system . this derivative is represented by a parameterized 561 neural network function . an ODE solver takes the initial hidden state z(t0)at the starting time point t0and 565 integrates the hidden state derivative over time . this 569 framework can generate a hidden state at any given time point and effectively 570 handle continuous-time data . an adjoint is defined as 573 a(t) =L z(t), where Lrepresents the loss function . this characteristic makes it particularly useful for modeling continuous- 571 time dynamic systems . the adjoint sensitivity method is used to reduce memory requirements during backpropagation . the adjoint sensitivity method solves an augmented ODE backward in time . the 577 computation of gradients can be done without the need for backpropagation through the ODE solver operations . a gradient of Lwith can be computed using an adjoint and a solver . 580 we incorporate Neural ODEs into computer vision tasks for electron micrograph classification by segmenting an electron microscope into a sequence of patches . the model doesn’t have to store intermediate results (partial derivatives) from 579 forward propagation, resulting in a constant memory cost . the sequence length is determined 582 by the total number of patches generated through the tokenization of the electron micrograph . treating the input sequence of 584 patches as a continuous-time system enables Neural ODEs to capture the evolution of the patch 585 embeddings smoothly and continuously . this approach facilitates the causal modeling of 586 spatial relationships and transformations between consecutive patches by encoding them into patch 587 embeddings . the encoder layers capture the relationships and dependencies between the patches 590 in the image . our bidirectional representation 592 learning approach incorporates two separate Neural ODEs . each pass maintains its own hidden state, and the outputs of both passes are combined through a 595 gating mechanism . a sequence that processes the sequence from left 593 to right (forward pass) forward Neural ODE estimate of patch embedding at time 596 point t1aszf(t1) and the backward Neural . a gating mechanism 597 is implemented to regulate the information flow from zf (t1)andzb(t1 . adaptive ODE solvers can lead to 601 significant time consumption . the IRDM employs barycentric Lagrange interpolation[ 6] on a Chebyshev grid[ 94] to 604 approximate the solution of patch embeddings during the reverse-mode differentiation . IRDM enables us to reduce the computational 606 time during backpropagation while maintaining satisfactory learning accuracy . we 607 adopt a fixed-grid ODE solver, namely the fourth-order Runge-Kutta method[ 12] and implement the 608 interpolated reverse dynamic method . 610 6.9 Related Work 611 In this section, we will first review the evolution of graph neural networks . a particular focus will be on Graph Convolutional 613 Networks (GCN)[ 63] and their utilization in vision tasks . the landscape of computer vision has been 614 significantly shaped by convolutional networks(i.e., ConvNets or CNNs) which have brought about a 615 seismic shift in the field and established themselves as the predominant architecture . LeNet[ 67] significantly influenced the development and 617 popularity of ConvNets, paving the way for more advanced and deeper networks in subsequent years 618 across a broad spectrum of vision tasks . breakthrough advancements such as ResNet[ 50], 620 16 MobileNet[ 56], and NAS[ 116,109] have further shaped the landscape of CNN architectures . the vision transformer(ViT) has been a trailblazer, leading to the development 622 of a myriad of improved ViT variants[ 31]. these improvements encompass pyramid architectures[ 71, 623 98], local attention mechanisms[ 46,71], and position encoding techniques[ 103]. Graph Neural Networks (GNNs) originated from the early work of 628 Scarselli and Gori et al. [ 80] . the concept of spatial graph convolutional networks 629 with non-recursive layers has been introduced . spatial GCNs have 630 seen numerous adaptations and improvements . spectral graph theory has been grounded in 632 networks . these networks were first introduced in a study by Bruna et al.[11] Graph Convolutional Networks (GCNs) have been 635 applied to diverse tasks . point clouds refer to sets of 3D points derived from LiDAR scans . 66,100,108 have been leveraged for classification and segmentation . scene graph 638 generation involves parsing an input image into a graph representation that delineates objects and their 639 interrelationships . 640 have been instrumental in facilitating human action recognition tasks by analyzing graphs representing 641 linked human joints . current frameworks in semiconductor manufacturing sector fall 642 short in various aspects . many existing 643 solutions fail to capitalize on the detailed analysis achievable through the synergy of patch sequences 644 and vision graphs at different scales in electron micrographs . the industry has yet to fully embrace the utilization of 647 large language models (LLMs) in generating technical descriptions of nanomaterials . a strategy that 648 can significantly deepen domain-specific insights critical for nanomaterial identification tasks . 649 glaring gap in integration of image-based and linguistic insights renders current architectures less 650 comprehensive and nuanced . the 651 proposed framework represents a pioneering approach to automatic nanomaterial 652 identification, addressing the prevailing challenges in semiconductor manufacturing processes. at 653 its core, it employs a hierarchical network fusion architecture that amalgamates two diverse 654 representations of electron micrographs . these representations undergo iterative refinement through a layered, inverted pyramid structure . the framework introduces a zero-shot 657 chain-of-thought (Zero-Shot CoT) prompting technique that uses large language models to generate detailed technical descriptions of nanomaterials . these descriptions serve as auxiliary information that bolsters identification tasks . the framework aims to facilitate a more comprehensive and 661 nuanced analysis of electron micrographs . it holds significant promise for advancements in 662 the semiconductor industry . 663 17 Table 8: LLM-retrieved text of GPT-3.5 for natural language queries about MEMS devices. Micro-Electro-Mechanical Systems, commonly known as MEMS, is a cutting-edge technology that integrates miniaturized mechanical and electromechanical elements with electronics on a single silicon chip or substrate . these systems typically consist of components with dimensions ranging from micrometers to millimeters . MEMS devices have revolutionized various industries due to their unique capabilities, compact size, low power consumption, and cost-effectiveness . they enable the creation of tiny, sophisticated systems with enhanced functionalities, making them indispensable in numerous applications . gyro- scopes, and magnetometers in smartphones enable motion sensing, orientation detection, and navigation . MEMS microphones are widely used for voice and audio input in smartphones, laptops and other gadgets . accelerometers and gyroscopes provide data for advanced driver assistance systems and vehicle navigation . inertial sensors, such as ac- celerometers, are vital for aircraft and spacecraft stabilization, guidance and control . MEMS sensors are essential components in robotics and autonomous systems . they provide feedback for motion control, bal-ance, and obstacle detection, enabling robots to navigate and interact with their environment safely . sensors are used for precise measurement, monitoring, and feedback control in manufacturing processes . MEMS technology has been instrumental in miniaturization of RF switches, tunable capacitors, and filters . energy harvesters are used to capture and convert ambient energy sources such as vibrations, solar, and thermal energy into usable electrical power for low-power electronic devices . the importance of MEMS stems from their ability to offer scalable, high-performance, and cost-effective solutions for various applications . the continuous advancement in MEMS fabrication techniques and materials has opened up new possi- bilities for even more innovative applications in the future . Query prompt LLM-retrieved text Definition and Structure: De-fine the MEMS and describe its typical structure at the nanoscale . ?Definition of MEMS: Micro-Electro-Mechanical Systems (MEMS) refers to a class of miniaturized devices and systems that integrate micro-scale mechanical components, electrical circuits, and some- times optical elements on a single substrate . MEMS devices exhibit a wide variety of structures and designs, each tailored to their specific application . they are characterized by their small size, with components ranging from micrometers to millimeters, and often operate in the micro/nano scale . MEMS structures often involve me-chanical components with dimensions in the micrometer range and electrical connections at the nanoscale level . silicon wafers are commonly used due to their excellent mechanical properties, compatibility with semiconductor processes, and availability in various sizes . mechanical components: MEMS devices consist of micro or nano- scale mechanical elements that can move or respond to external stim- uli . they may include beams, cantilevers, diaphragms, membranes, gears, and more . sensors can be electrostatic, piezoelectric, ther- mal, magnetic, or other types, depending on the required movement and sensitivity . common MEMS sensors include accelerometers, gyroscopes, pressure sensors, and temperature sensors . nanoscale electrical interconnects provide neces- sary connections between the MEMS components and the external circuits or systems . these connections are usually made using metal traces or vias . they are often used to transform mechanical motion or physical parameters into electrical signals . integrated control electronics are present on the same chip to process, amplify, and transmit signals to and from mechanical components and sensors . the choice of materials, such as silicon, polymers, metals, and composites, is critical to achieving the desired mechani- cal and electrical properties . the combination of these components and their precise integration on a single substrate allows MEMS de- vices to perform a wide range of functions across various industries, making them a fundamental technology in the world of miniaturized electronics and sensors . several methods are used to synthesize or fabricate MEMS devices . each with its own advantages and limitations . Bulk Micromachining: Advantages: (a) Well-established and widely used method . (b) Suitable for fabricating simple, 2D MEMS structures . surface micromachining: Advantages: (a) Enables the fabrication of complex 3D structures, (b) Suitable for high-volume production due to batch processing capabilities, and (c) Can integrate multiple layers of different materials . sacrificial layer techniques can be more complicated and time-consuming than bulk micromachining . material choices are often limited to specific combinations suitable for saturation release . a variety of materials are available in a wide range of sizes . LIGA (Lithography, Electroplating, and Molding): Advantages: (a) Capable of fabricating high-aspect-ratio structures with excellent pre-cision, (b) Suitable for mass production of microstructures, and (c) Compatible with various materials . Limitations: a) Complex and costly process due to multiple steps involved . Soft Lithography: Advantages: (a) Simple and cost-effective tech-nique, (b) Suitable for rapid prototyping and small-scale production, and (c) Not suitable for high-temperature or harsh environments. silicon-on-insulator (SOI) technology: Advantages: (a) Provides high mechanical stability and isolation . (b) Suitable for integrating MEMS and CMOS components on same chip . nanolithography and nanofabrication: Advantages: (a) Enables fabri- cation of nanoscale MEMS devices with high precision; (b) Allows for the development of novel and highly sensitive sensors and actuators; (c) Can be used to create complex nanostructures and patterns . 3D Printing/Additive Manufacturing: Advantages: (a) Enables rapid prototyping and customization of MEMS devices, (b) Supports the creation of complex 3D geometries and intricate structures . reduces the need for complex lithography and etching steps . the choice of synthesis method depends on the requirement of material properties, volume of production, and budget constraints . Query prompt LLM-retrieved text Properties: Highlight the unique physical, chemical, and electronic properties exhibited by MEMS in this nanomaerial category . ?MEMS (Micro-Electro-Mechanical Systems) exhibit several unique physical, chemical, and electronic properties at the nanoscale . the most obvious property of MEMS is their minia- ture size, typically from micrometers to millimeters . this reduced scale allows for compact, lightweight, and portable devices, which is not achievable in their bulk counterparts. MEMS devices have a higher surface-to-volume ratio compared to bulk devices . this increased surface area enhances interactions with the surrounding environment, leading to improved sensitivity in sensors and more efficient reactions in chemical and biological applications . nanoscale mechanical components can have enhanced flexibility, higher resilience, and reduced inertia due to their reduced mass and size . properties are advantageous in applications such as ac- celerometers and gyroscopes . electrical properties are commonly used for sensing and actuation in MEMS devices . some devices, especially those incorporat- ing optical elements, can exhibit novel optical properties due to the interaction of light with nanoscale structures . electrical properties include high sensitivity to electrical sig- nals . nanomaterials may have altered mechanical, electrical, and optical characteristics due to quantum effects and surface interactions . this enables the devel- opment of miniaturized optical sensors, displays, and communication systems . materials can exhibit different properties than at the bulk level . MEMS sensors at the nanoscale are highly sensitive to various stimuli . this sensitivity enables precise measurements and detections . reduced size and lower power requirements make them more energy-efficient com- pared to bulk systems . MEMS devices can integrate multiple functionalities, such as sensing, actuation, and signal processing, on a single chip . this integration capability allows for the development of complex, multifunctional systems in a compact form factor . the unique physical, chemical, and electronic properties of MEMS at the nanoscale make them ideal for a wide range of applications, including sensors, actuators, and biomedical devices . Query prompt LLM-retrieved text Applications: Explore the wide range where MEMs are used . MEMS (Micro-Electro-Mechanical Systems) have found extensive applications across various industries due to their unique properties and miniaturized form factor . discuss their potential impact in fields such as electronics, energy, medicine, environmental reme- diation, etc. MEMS accelerometers and gy- roscopes in smartphones and wearable devices enable motion sensing and orientation detection for gaming, navigation, and fitness tracking . MEMS-based displays, such as digital micromirror de- vices, are used in projectors and digital cinema. MEMS-based lab-on-a-chip devices allow for rapid and precise analysis of biological samples . microflu-idic MEMS devices are used for drug delivery systems, implantable medical devices, and micro-pumps for controlled drug release . MEMS accelerometers and gyro- scopes are essential components in automotive safety systems, such as airbags, electronic stability control, and tire pressure monitoring systems . pressure sensors are used in engine manage- ment and emissions control systems to optimize performance and fuel efficiency . MEMS sensors are used for moni- toring air quality, temperature, humidity, and gas concentrations in environmental monitoring systems . MEMS devices enable remote sensing and data collection for climate research and weather forecasting and climate research . gyroscopes and accelerometers are critical components in aerospace applications for attitude control, navigation, and guidance systems . pressure sensors are used in altitude and airspeed measurements in aircraft, and infrared imaging devices are utilized in night vision systems for military and security applications . energy harvesters convert ambient en- ergy, such as vibrations or thermal gradients, into electrical power . sensors are used for con- dition monitoring, predictive maintenance, and feedback control in manufacturing and industrial processes . MEMS sensors and actuators enable precise motion control and sensing in robots . they contribute to increased efficiency, improved functionality, reduced energy consumption, and improved safety in various applications . the potential impact of MEMS in these fields is immense. we can expect further integration, miniaturization, and performance improvements, leading to even more innovative applications across industries and benefiting society as whole . Query prompt LLM-retrieved text Applications: Explore the wide range of applications where MEMs are used . discuss potential impact in fields such as electronics, energy, medicine, environmental reme- diation, etc.Surface modification plays a crucial role in tailoring the properties of MEMS devices in the nanomaterials category . functionalization involves attaching or grafting specific molecules or functional groups onto the surface of MEMS de- vices . this process enhances the surface’s chemical reactivity and al- lows for specific interactions with target substances . functionalizing the surface with biomolecules enables biosensing applications for disease detection and medical diagnostics . the surface functionalization of MEMS gas sensors with specific materials enhances their selectivity and sensitivity to target gases . surface coating involves depositing thin layers of materials onto the MEMS surface to alter its properties . some coating methods include physical vapor deposition (PVD) and atomic layer deposition . coatings can be func- tional or protective (passive) in nature . anti-stiction coatings reduces stiction and friction, which is crucial for reliable operation in micro-mechanical devices . Coatings can protect devices from chem- ical corrosion or degradation, increasing their durability and lifespan in harsh environments. doping involves introducing impurity atoms into the ma- terial’s surface to modify its electrical properties . this strategy is commonly used in semiconductors to create p-type or n-type regions and adjust the device’s conductivity. the sensitivity, response time, and power consumption of MEMS devices can be optimized for specific applications . nanopatterning involves creating specific patterns or nanostructures on the MEMS surface . techniques like electron beam lithography, nanoimprint lithographie, and nanocontact printing can be used to fabricate intricate patterns . nanopatterning enables applications such as: Enhanced Adhesion: Nanostructures can improve adhesion be- tween MEMS components and bonding surfaces . nanostructured sur- faces can achieve superhydrophobic properties, repelling water and other liquids . Query prompt LLM-retrieved text Toxicity and Safety: Address the potential health and envi- ronmental concerns associated with MEMS in this nanomateri- als category . a nanomatteri- ca category is a category of nanomEMS devices that can be used for natural language queries . discuss studies on their toxicity, risk assessment, and safety measures to mitigate potential hazards . concerns about the po- tential health and environmental impacts associated with MEMS devices in the nanomaterials category . some nanomaterial and fabrication pro- cesses used in production can raise toxicity and safety issues. nanomaterial Toxicity: nanomaterials can poten-tially pose health and environmental risks if they are released into the environment or come into contact with living organisms . a nanomaterial is a small size and increased surface area . researchers and regulatory bodies conduct risk assessments to assess potential hazards . these assessments consider expo- sure pathways, potential toxicity, and the likelihood of adverse effects . risk assessments are essential to assess the potential harm caused by exposure to nanomaterials in MEMS devices . risk assessment helps in identifying potential risks and implementing appropriate safety measures to minimize or eliminate hazards . safety measures include: engineering controls: Implementing engineering controls during the fabrication process to minimize exposure to hazardous materials and ensure safe handling and disposal of nanomaterials . Personal Protective Equipment (PPE): Providing employees with ap- propriate PPE to prevent inhalation or skin contact with nanomaterials during fabrication or handling of MEMS devices . environmental regulations: Complying with environmental regulations and guidelines for the safe disposal of waste materials generated during MEMS fabrication . environmental impact assessments help identify potential risks and provide insights into how to design MEMS devices with minimal environmental impact . Continued research into the toxicity of nano- materials and the potential hazards associated with the devices is essential to identifying potential risks . new materials and fabrica-tion processes may emerge as the technology advances . nanomaterials may offer exciting possibilities for various applications . it is crucial to address potential health and environmental concerns associated with nanomaterial . if you have any questions, please contact us today . toxicity studies, risk assessment and safety measures are essential steps to ensure the responsible and sustainable development and use of MEMS tech- nology . by prioritizing safety and environmental considerations, the benefits can be harnessed while minimizing potential risks . emerging technolo- gies, challenges, and areas of active exploration are driven by a combination of techno- logical advancements, societal demands, and industry needs . future directions: Discuss cur- rent research trends and fu-ture prospects for MEMS . the proliferation of IoT and smart devices is fueling the demand for MEMS sensors and actuators that are smaller, more power-efficient, and capable of pro-viding precise data . there are some key areas of active exploration and emerging technologies in the field of MEMS . research is focused on developing low-power, miniaturized MEMS devices for applications in smart homes, wear- able devices, environmental monitoring, and industrial automation . b) Energy harvesting: energy harvesting using MEMS device is a promising area of research . researchers are exploring the use of MEMS energy harvesters to capture ambient energy from vibrations, thermal gradients, and solar radiation to power low-energy electronic devices and sensors . MEMS-NEMS integration: The integration of the MEMS with NEMS is an area of active exploration . nanomaterials and nanofabrication are enabling the development of novel MEMS devices with enhanced functionalities and improved perfor- mance . the new devices are able to be used in sensing and actuation applications . researchers are exploring nanomaterial-based MEMS devices for applications in gas sensing, chemical detection, and bio-imaging . 3D printing and additive manufacturing is being investigated for rapid prototyping and fabrication of complex MEMS structures . this technology allows for greater design flexibility and customization . despite the promising future of MEMS technology, some challenges need to be addressed: (a) integration complexity: as MEMS devices become more sophisticated, in- tegration challenges arise . the integration of different materials, electronics, and sensors on a single chip requires precise fabrication techniques and design optimization . materi- als compatibility, stiction, and packaging issues need to be addressed . lack of standardized processes and testing methods can hinder widespread adoption and commercialization of MEMS devices . the lack of standardization can hinder their widespread adoption . standardization efforts are essential to ensure consistent performance and compatibility across different MEMS devices . scaling down devices to nanoscale dimensions presents manufac- uring challenges and can increase production costs . cost-effective fabrication methods for mass production are crucial for widespread adoption . MEMS-based medical devices are expected to revolutionize diagnostics, treatment, and personalized medicine, leading to better patient outcomes and healthcare efficiency . sensors and actuators will play a crucial role in enabling autonomous vehicles, drones, and robotics, advancing automation and safety across industries . the future of MEMS technology holds great promise, with advancements in nanomaterials, 3D printing, IoT, and healthcare applications driving innovation . addressing current challenges and promoting collaboration between researchers, industry, and regulatory bodies will be key to unlock the full potential of the technology . Technical Disclosur e Commons Defensiv e Publications Series 15 No v 2024 Semiconduct or Yield Impr ovement b y Enabling Use of F aulty Chips for LLM Inf erence Rober to Lupi Follow this and additional works at: https://www.tdcommons.or g/dpubs_series Recommended Citation Lupi, Rober . it has been accepted for inclusion in Def ensiv e Publications Series b y an authoriz ed administr ator of T echnical Disclosur e Commons . the disclosure describes techniques that enable the use of faulty semiconductor chips to achieve reliable large language model performance . the output of a faulty chip is subjected to a chip-specific transformation that corrects errors . errors are applied at a relatively large scale, e.g., for an entire LLM layer . the use of unreliable components to achieve reliable computing reduces the rejection rate . KEYWORDS  Large language model (LLM)  Matrix multiplication . Matmul unit  Error correction  Silent data corruption (SDC) .  Fault tolerant computing . simpler LLMs are based on 3 -level logic, elementary operations, prun ing low -value interconnections, etc. [1, 2] to reduce energy demands . chip die size and energy consumption are constrained by chips die size . 2Lupi: Semiconductor Yield Improvement by Enabling Use of Faulty Chips f Published by Technical Disclosure Commons, 2024 Silent data corruption refers to computing errors that originate from hardware defects . an impacted central processing unit may miscalculate 1+1 as 3. disclosure describes techniques that enable the use of faulty semiconductor chips to achieve reliable LLM performance . the error -correcting transformations are applied at a relatively large scale, e.g., for an entire LLM layer rather than at the level of a single matrix multiplication (matmul) block . the use of unreliable components to achieve reliable com puting reduces the rejection rate and increases the yield of semiconductor manufacturing . costly die -size and energy consumption redundancies are reduced or eliminated with the scale at which error correction is applied . chips that cross a relatively low threshold of reliability are accepted . a chip with a few high -quality matmul blocks and several error -prone blocks can be accepted, according to the 3Defensive Publications Series . the faulty blocks are tested (104) using specific patterns of inputs with known outputs . a transformation is computed to correct the erro r, e.g., to route around the hardware fault . forward -forward can be vulnerable to skewed inputs . the input patterns can be controlled to be balanced . positive and negative samples are passed through the same pathways on the chip, such that they statistically experience the same faults on large volumes of data . errors can be corrected for an entire LLM layer instead of a single matmul block . corrections can be applied at smaller -sized blocks . training minimizes a composite multi -objective loss function to generate the correct output . recursion can proceed beyond a single chip to rack -level components . a data center can reliably operate an LLM with a combination of performant and faulty accelerators . the training procedure recursively proceeds to larger -sized blocks . 4Lupi: Semiconductor Yield Improvement by Enabling Use of Faulty Chips f Published by Technical Disclosure Commons, 2024 to enable a higher component density . the initial warm -up cost can be insubstantial compared to the savings . error correction can be done once at the factory . a fingerprint can be computed and an adjustment can be pre-compiled for the LLM mo del . when a faulty block receives an input signal (202), its initial output is erroneous . the output of a faulty chip is subjected to a chip -specific transformation (206) that corrects errors . this disclosure describes techniques that enable the use of faulty semiconductor chips to achieve reliable large language model performance . Error -correc ting transformations are applied at a relatively large scale, e.g., for an entire LLM layer rather than at the level of a single matrix multiplication block . the use of unreliable components to achieve reliable computing reduces the rejection rate . error correction is applied to costly die -size and energy consumption redundancies . error correction can be applied to the scale at which errors are applied . the scale of error correction will reduce the cost of die-size redundancy and reduce energy consumption .
